import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression, LogisticRegression, BayesianRidge
from sklearn.metrics import r2_score, accuracy_score, mean_squared_error, classification_report
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree
from sklearn.datasets import make_classification, make_regression
from sklearn.model_selection import train_test_split
from sklearn.inspection import DecisionBoundaryDisplay

from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import pymc as pm
import arviz as az
import seaborn as sns




# Fonction pour g√©n√©rer des donn√©es synth√©tiques
def generate_data(case, n_samples=100, noise_level=0.5):
    np.random.seed(42)
    X = np.linspace(0, 10, n_samples)
    if case == "lin√©aire":
        y = 2 * X + 3 + np.random.normal(0, noise_level, n_samples)
    elif case == "non_lin√©aire":
        y = 0.5 * X**2 - 0.1 * X**3 + np.random.normal(0, noise_level, n_samples)
    elif case == "h√©t√©rosc√©dastique":
        y = 2 * X + 3 + np.random.normal(0, noise_level * X, n_samples)
    elif case == "valeurs_extr√™mes":
        y = 2 * X + 3 + np.random.normal(0, noise_level, n_samples)
        y[-10:] += np.random.normal(0, 10, 10)  # Ajout de valeurs extr√™mes
    
    return X.reshape(-1, 1), y


# Sidebar pour les param√®tres
st.sidebar.header("Param√®tres des R√©gressions")
case = st.sidebar.selectbox("Type de donn√©es", 
                           ["lin√©aire", "non_lin√©aire", "h√©t√©rosc√©dastique", "valeurs_extr√™mes"],
                           help="Choisissez le type de relation entre X et y")
n_samples = st.sidebar.slider("Nombre d'√©chantillons", 50, 500, 100)
noise_level = st.sidebar.slider("Niveau de bruit", 0.1, 2.0, 0.5)
n_iter = st.sidebar.slider("Nombre d'it√©rations MCMC", 500, 5000, 2000)

# G√©n√©ration des donn√©es
X, y = generate_data(case, n_samples, noise_level)
df = pd.DataFrame({'X': X.flatten(), 'y': y})


# Titre de l'application
st.title("Visualisation de la R√©gression Lin√©aire : Quand √ßa marche et quand √ßa ne marche pas")

# Fonction pour g√©n√©rer et tracer les donn√©es
def plot_regression(X, y, title, subplot_pos):
    # Entra√Ænement du mod√®le
    model = LinearRegression()
    model.fit(X, y)
    y_pred = model.predict(X)
    
    # Calcul du R¬≤
    r2 = r2_score(y, y_pred)
    
    # Visualisation
    plt.subplot(1, 2, subplot_pos)
    plt.scatter(X, y, color='blue', label='Donn√©es r√©elles')
    plt.plot(X, y_pred, color='red', label='R√©gression lin√©aire')
    plt.title(f"{title}\nR¬≤ = {r2:.3f}")
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.legend()
    

# G√©n√©rer les donn√©es
np.random.seed(42)

# 1. Cas o√π la r√©gression lin√©aire fonctionne bien (relation lin√©aire)
X_linear = np.linspace(0, 10, n_samples).reshape(-1, 1)
y_linear = 2 * X_linear + 1 + np.random.normal(0, 1, (n_samples, 1))  # y = 2x + 1 + bruit

# 2. Cas o√π la r√©gression lin√©aire fonctionne mal (relation non-lin√©aire)
X_nonlinear = np.linspace(0, 10, n_samples).reshape(-1, 1)
y_nonlinear = np.sin(X_nonlinear) + np.random.normal(0, 0.1, (n_samples, 1))  # y = sin(x) + bruit

# Interface Streamlit
st.write("### R√©gression lin√©aire sur une relation lin√©aire")
st.write("Ici, les donn√©es suivent une tendance lin√©aire (y ‚âà 2x + 1 + bruit). La r√©gression lin√©aire est adapt√©e.")
plt.figure(figsize=(12, 5))
plot_regression(X_linear, y_linear, "R√©gression sur donn√©es lin√©aires", 1)


# Afficher le graphique
plt.tight_layout()
st.pyplot(plt)

# Explications suppl√©mentaires
st.write("""
### Interpr√©tation :
- **R¬≤ (coefficient de d√©termination)** : Mesure √† quel point le mod√®le explique la variance des donn√©es. 
  - Proche de 1 : bon ajustement (cas lin√©aire).
  - Proche de 0 ou n√©gatif : mauvais ajustement (cas non-lin√©aire).
- La r√©gression lin√©aire suppose une relation lin√©aire entre X et Y. Si cette hypoth√®se n'est pas respect√©e, le mod√®le sera inefficace.
""")

# Titre de l'application
st.title("Visualisation de la R√©gression Logistique : Quand √ßa marche et quand √ßa ne marche pas")

# Fonction pour g√©n√©rer et tracer les donn√©es
def plot_logistic_regression(X, y, title, subplot_pos):
    # Entra√Ænement du mod√®le
    model = LogisticRegression()
    model.fit(X, y)
    y_pred = model.predict(X)
    
    # Calcul de l'accuracy
    accuracy = accuracy_score(y, y_pred)
    
    # Cr√©ation d'une grille pour visualiser la fronti√®re de d√©cision
    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))
    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    
    # Visualisation
    plt.subplot(1, 2, subplot_pos)
    plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap='coolwarm', label='Donn√©es')
    plt.title(f"{title}\nAccuracy = {accuracy:.3f}")
    plt.xlabel("X1")
    plt.ylabel("X2")
    plt.legend()

# G√©n√©rer les donn√©es
np.random.seed(42)

# 1. Cas o√π la r√©gression logistique fonctionne bien (donn√©es lin√©airement s√©parables)
X_linear = np.vstack([
    np.random.normal(2, 1, (n_samples // 2, 2)),  # Classe 0
    np.random.normal(6, 1, (n_samples // 2, 2))   # Classe 1
])
y_linear = np.hstack([np.zeros(n_samples // 2), np.ones(n_samples // 2)])

# 2. Cas o√π la r√©gression logistique fonctionne mal (donn√©es non lin√©airement s√©parables)
X_nonlinear = np.vstack([
    np.random.normal(0, 1, (n_samples // 2, 2)),  # Classe 0 au centre
    np.random.normal(0, 3, (n_samples // 2, 2))   # Classe 1 autour
])
y_nonlinear = np.hstack([np.zeros(n_samples // 2), np.ones(n_samples // 2)])

# Interface Streamlit
st.write("### Exemple 1 : R√©gression logistique sur des donn√©es lin√©airement s√©parables")
st.write("Ici, les deux classes sont bien s√©par√©es par une fronti√®re lin√©aire. La r√©gression logistique est adapt√©e.")
plt.figure(figsize=(12, 5))
plot_logistic_regression(X_linear, y_linear, "Donn√©es lin√©airement s√©parables", 1)

st.write("### Exemple 2 : R√©gression logistique sur des donn√©es non lin√©airement s√©parables")
st.write("Ici, les classes sont m√©lang√©es de mani√®re non lin√©aire (une classe entoure l'autre). La r√©gression logistique √©choue.")
plot_logistic_regression(X_nonlinear, y_nonlinear, "Donn√©es non lin√©airement s√©parables", 2)

# Afficher le graphique
plt.tight_layout()
st.pyplot(plt)

# Explications suppl√©mentaires
st.write("""
### Interpr√©tation :
- **Accuracy** : Proportion de pr√©dictions correctes. 
  - Proche de 1 : bon ajustement (cas lin√©airement s√©parable).
  - Plus faible : mauvais ajustement (cas non lin√©airement s√©parable).
- La r√©gression logistique suppose que les classes peuvent √™tre s√©par√©es par une fronti√®re lin√©aire dans l'espace des caract√©ristiques. Si cette hypoth√®se n'est pas respect√©e, le mod√®le sera inefficace.
- Pour les donn√©es non lin√©airement s√©parables, des mod√®les comme les SVM avec noyau ou les r√©seaux de neurones sont plus adapt√©s.
""")

# Titre de l'application
st.title("Visualisation de la R√©gression Polynomiale : Quand √ßa marche et quand √ßa ne marche pas")

# Fonction pour g√©n√©rer et tracer les donn√©es
def plot_polynomial_regression(X, y, degree, title, subplot_pos):
    # Transformation polynomiale
    poly = PolynomialFeatures(degree=degree)
    X_poly = poly.fit_transform(X)
    
    # Entra√Ænement du mod√®le
    model = LinearRegression()
    model.fit(X_poly, y)
    
    # Pr√©diction
    X_smooth = np.linspace(X.min(), X.max(), 300).reshape(-1, 1)
    X_smooth_poly = poly.transform(X_smooth)
    y_pred_smooth = model.predict(X_smooth_poly)
    y_pred = model.predict(X_poly)
    
    # Calcul du R¬≤
    r2 = r2_score(y, y_pred)
    
    # Visualisation
    plt.subplot(1, 2, subplot_pos)
    plt.scatter(X, y, color='blue', label='Donn√©es r√©elles')
    plt.plot(X_smooth, y_pred_smooth, color='red', label=f'R√©gression polynomiale (deg={degree})')
    plt.title(f"{title}\nR¬≤ = {r2:.3f}")
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.legend()

# G√©n√©rer les donn√©es
np.random.seed(42)

# 1. Cas o√π la r√©gression polynomiale fonctionne bien (relation quadratique)
X_poly = np.linspace(-3, 3, n_samples).reshape(-1, 1)
y_poly = 2 * X_poly**2 - 3 * X_poly + 1 + np.random.normal(0, 1, (n_samples, 1))  # y = 2x¬≤ - 3x + 1 + bruit

# 2. Cas o√π la r√©gression polynomiale fonctionne mal (relation bruit√©e/non polynomiale)
X_noisy = np.linspace(0, 10, n_samples).reshape(-1, 1)
y_noisy = np.sin(X_noisy) + np.random.normal(0, 2, (n_samples, 1))  # y = sin(x) + bruit fort

# Interface Streamlit
st.write("### Exemple 1 : R√©gression polynomiale sur une relation quadratique")
st.write("Ici, les donn√©es suivent une tendance quadratique (y ‚âà 2x¬≤ - 3x + 1 + bruit). Une r√©gression polynomiale de degr√© 2 est adapt√©e.")
plt.figure(figsize=(12, 5))
plot_polynomial_regression(X_poly, y_poly, 2, "R√©gression sur donn√©es quadratiques", 1)

st.write("### Exemple 2 : R√©gression polynomiale sur une relation bruit√©e/non polynomiale")
st.write("Ici, les donn√©es suivent une tendance sinuso√Ødale avec beaucoup de bruit (y ‚âà sin(x) + bruit). Une r√©gression polynomiale √©choue √† bien capturer la relation.")
plot_polynomial_regression(X_noisy, y_noisy, 2, "R√©gression sur donn√©es bruit√©es", 2)

# Afficher le graphique
plt.tight_layout()
st.pyplot(plt)

# Explications suppl√©mentaires
st.write("""
### Interpr√©tation :
- **R¬≤ (coefficient de d√©termination)** : Mesure √† quel point le mod√®le explique la variance des donn√©es.
  - Proche de 1 : bon ajustement (cas quadratique).
  - Plus faible : mauvais ajustement (cas bruit√©/non polynomial).
- La r√©gression polynomiale est efficace quand la relation entre X et Y peut √™tre approxim√©e par un polyn√¥me (ex. quadratique, cubique).
- Elle √©choue si la relation est fortement non polynomiale (ex. sinuso√Ødale) ou si le bruit domine le signal.
- Pour le second cas, des mod√®les comme les splines ou les s√©ries de Fourier seraient plus adapt√©s.
""")

#st.set_page_config(page_title="R√©gression Bay√©sienne", layout="wide")
st.title("Visualisation des Mod√®les de R√©gression Bay√©sienne")





# Affichage des donn√©es
st.subheader("Visualisation des Donn√©es")
fig, ax = plt.subplots(figsize=(10, 5))
sns.scatterplot(data=df, x='X', y='y', ax=ax)
ax.set_title(f"Donn√©es {case} (bruit={noise_level})")
st.pyplot(fig)

# R√©gression bay√©sienne avec pymc3
st.subheader("Mod√©lisation Bay√©sienne avec PyMC3")

with st.expander("D√©tails du mod√®le PyMC3"):
    st.write("""
    Nous utilisons un mod√®le hi√©rarchique bay√©sien avec:
    - Prior normal pour les coefficients
    - Prior half-normal pour l'√©cart-type
    - √âchantillonnage MCMC avec NUTS
    """)

try:
    with pm.Model() as bayesian_model:
        # Priors
        alpha = pm.Normal('alpha', mu=0, sigma=10)
        beta = pm.Normal('beta', mu=0, sigma=10)
        sigma = pm.HalfNormal('sigma', sigma=1)
        
        # Relation lin√©aire
        mu = alpha + beta * X.flatten()
        
        # Likelihood
        y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=y)
        
        # Sampling
        trace = pm.sample(n_iter, tune=1000, chains=2, return_inferencedata=True)
    
    # Affichage des r√©sultats
    st.write(az.summary(trace, hdi_prob=0.95))
    
    try:
        # Create figure with proper layout
        fig, axes = plt.subplots(3, 2, figsize=(12, 12))
        fig.suptitle('MCMC Trace and Density Plots', y=1.02)
        
        # Define reference lines (example values - adjust based on your model)
        ref_lines = [
            ('alpha', {}, 3.0),  # Format: (var_name, {}, reference_value)
            ('beta', {}, 2.0),
            ('sigma', {}, 1.0)
        ]
        
        # Plot traces with reference lines
        az.plot_trace(
            trace,
            var_names=['alpha', 'beta', 'sigma'],
            lines=ref_lines,
            compact=True,
            combined=False,
            axes=axes,
            legend=True,
            plot_kwargs={'alpha': 0.8}  # Make lines slightly transparent
        )
        
        # Customize plot appearance
        for i, param in enumerate(['alpha', 'beta', 'sigma']):
            axes[i, 0].set_title(f'Trace for {param}')
            axes[i, 1].set_title(f'Density for {param}')
            axes[i, 0].set_ylabel('Sample value')
            axes[i, 1].set_ylabel('Density')
        
        plt.tight_layout()
        st.pyplot(fig)
        
    except Exception as e:
        st.error(f"Trace plotting failed: {str(e)}")
        st.write("Attempting simplified plotting...")
        
        try:
            # Fallback to simple plotting without reference lines
            fig = az.plot_trace(
                trace,
                var_names=['alpha', 'beta', 'sigma'],
                compact=True,
                legend=True
            )
            st.pyplot(fig)
        except Exception as simple_error:
            st.error(f"Simplified plotting also failed: {str(simple_error)}")
            st.write("Showing numerical summary instead:")
            st.write(az.summary(trace, hdi_prob=0.95))
        
        except Exception as e:
            st.warning(f"Visualisation compacte √©chou√©e: {str(e)}")
        
        # M√©thode alternative param√®tre par param√®tre
        for param in ['alpha', 'beta', 'sigma']:
            st.markdown(f"**{param}**")
            try:
                fig, axes = plt.subplots(1, 2, figsize=(10, 3))
                az.plot_trace(trace, var_names=[param], axes=axes)
                st.pyplot(fig)
            except:
                st.write(f"Impossible d'afficher les traces pour {param}")
        
        # Visualisation de la pr√©diction - VERSION CORRECTE
        st.subheader("Pr√©dictions du Mod√®le")
    
    # Pr√©dictions post√©rieures
    with bayesian_model:
        ppc = pm.sample_posterior_predictive(
            trace,
            var_names=['y_obs'],
            random_seed=42,
            progressbar=True
        )
    
    # Extraction des pr√©dictions
    if isinstance(ppc, dict) and 'y_obs' in ppc:
        # Format ancienne version PyMC3
        y_pred = ppc['y_obs'].mean(axis=0)
        y_hdi = az.hdi(ppc['y_obs'], hdi_prob=0.95)
    else:
        # Format nouvelle version PyMC
        ppc_samples = ppc.posterior_predictive['y_obs'].values
        ppc_samples = ppc_samples.reshape(-1, ppc_samples.shape[-1])
        y_pred = ppc_samples.mean(axis=0)
        y_hdi = az.hdi(ppc_samples, hdi_prob=0.95)
    
    # Visualisation
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.scatterplot(x=X.flatten(), y=y, ax=ax, label='Donn√©es')
    sns.lineplot(x=X.flatten(), y=y_pred, ax=ax, color='red', label='Pr√©diction moyenne')
    ax.fill_between(X.flatten(), y_hdi[:, 0], y_hdi[:, 1], color='red', alpha=0.3, label='Intervalle cr√©dible 95%')
    ax.set_title("Pr√©dictions avec Intervalles Cr√©dibles")
    ax.legend()
    st.pyplot(fig)
    
    # Calcul du RMSE
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    st.metric("RMSE", value=f"{rmse:.2f}")
    
    
except Exception as e:
    st.error(f"Erreur dans l'ajustement du mod√®le: {str(e)}")
    st.write("Le mod√®le bay√©sien rencontre des difficult√©s avec ce type de donn√©es.")


# Comparaison avec BayesianRidge de scikit-learn
st.subheader("Comparaison avec BayesianRidge (scikit-learn)")

with st.expander("√Ä propos de BayesianRidge"):
    st.write("""
    BayesianRidge est une impl√©mentation simplifi√©e de la r√©gression bay√©sienne qui:
    - Utilise des priors conjugu√©s (normaux-gamma)
    - Estime les param√®tres par maximisation de la vraisemblance marginale
    - Est plus rapide mais moins flexible que les approches MCMC
    """)

try:
    # Ajustement du mod√®l
    br = BayesianRidge(compute_score=True)
    br.fit(X, y)
    y_pred_br = br.predict(X)
    
    # Affichage des coefficients
    coefs = pd.DataFrame({
        'Param√®tre': ['alpha', 'beta', 'sigma'],
        'Valeur': [br.intercept_, br.coef_[0], np.sqrt(1/br.alpha_)]
    })
    st.write(coefs)
    
    # Visualisation
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.scatterplot(x=X.flatten(), y=y, ax=ax, label='Donn√©es')
    sns.lineplot(x=X.flatten(), y=y_pred_br, ax=ax, color='green', label='BayesianRidge')
    ax.set_title("Pr√©dictions avec BayesianRidge")
    ax.legend()
    st.pyplot(fig)
    
    # Calcul du RMSE
    rmse_br = np.sqrt(mean_squared_error(y, y_pred_br))
    st.metric("RMSE (BayesianRidge)", value=f"{rmse_br:.2f}")
    
except Exception as e:
    st.error(f"Erreur avec BayesianRidge: {str(e)}")

# Interpr√©tation des r√©sultats
st.subheader("Interpr√©tation")
if case == "lin√©aire":
    st.success("""
    üéØ **Le mod√®le bay√©sien fonctionne bien** pour des donn√©es lin√©aires avec bruit homosc√©dastique.
    - Les intervalles cr√©dibles couvrent bien les donn√©es
    - Les param√®tres sont bien estim√©s
    - Les diagnostics MCMC montrent une bonne convergence
    """)
elif case == "non_lin√©aire":
    st.warning("""
    ‚ö†Ô∏è **Le mod√®le lin√©aire bay√©sien est mal adapt√©** aux relations non-lin√©aires.
    - La relation sous-jacente est quadratique/cubique
    - Un mod√®le polynomial bay√©sien serait plus appropri√©
    - Les intervalles cr√©dibles ne capturent pas bien la variabilit√©
    """)
elif case == "h√©t√©rosc√©dastique":
    st.warning("""
    ‚ö†Ô∏è **Le mod√®le standard suppose une variance constante** (homosc√©dasticit√©).
    - Pour des donn√©es h√©t√©rosc√©dastiques, envisagez:
        - Une mod√©lisation explicite de la variance
        - Une transformation des donn√©es
        - Une famille de distribution diff√©rente
    """)
elif case == "valeurs_extr√™mes":
    st.warning("""
    ‚ö†Ô∏è **Les valeurs extr√™mes influencent fortement** le mod√®le bay√©sien gaussien.
    - Envisagez une distribution √† queues plus √©paisses (Student-t)
    - Ou un mod√®le robuste aux outliers
    """)

# Conclusion
st.markdown("""
## Quand utiliser la r√©gression bay√©sienne?

‚úÖ **Fonctionne bien quand:**
- Petits √©chantillons (utilisation efficace de l'information)
- Incertitude √† quantifier (intervalles cr√©dibles)
- Information a priori disponible
- Relations lin√©aires ou l√©g√®rement non-lin√©aires

‚ùå **Moins adapt√© quand:**
- Tr√®s grandes bases de donn√©es (temps de calcul)
- Relations hautement non-lin√©aires (sans transformations)
- Bruit complexe (h√©t√©rosc√©dasticit√©, outliers)
- Sans information a priori pertinente
""")


st.title("Visualisation des Mod√®les de Moyennes Mobiles (MA)")
st.markdown("""
Ce d√©monstrateur montre quand les mod√®les de Moyennes Mobiles (MA) fonctionnent bien 
et quand ils √©chouent dans l'analyse pr√©dictive.
""")

# Sidebar controls
st.sidebar.header("Param√®tres Moyennes Mobiles")
ma_order = st.sidebar.selectbox("Ordre du mod√®le MA (q)", [1, 2, 3, 4, 5])
ma_window_size = st.sidebar.slider("Taille de la fen√™tre pour MA simple", 3, 50, 10)
ma_n_samples = st.sidebar.slider("Nombre d'√©chantillons", 50, 500, 200)
ma_noise_level = st.sidebar.slider("Niveau de bruit ", 0.1, 2.0, 0.5)

# Generate MA time series
def generate_ma_process(order, ma_n_samples, ma_noise_level):
    # Coefficients MA - nous utilisons des valeurs qui cr√©ent un processus stationnaire
    ma_params = np.array([0.5] * order)
    ar_params = np.array([])
    
    # G√©n√©rer le processus MA
    ma_process = ArmaProcess.from_coeffs(ar_params, ma_params)
    ma_series = ma_process.generate_sample(nsample=ma_n_samples, scale=ma_noise_level)
    
    # Ajouter une tendance pour voir quand MA √©choue
    trend = np.linspace(0, 5, ma_n_samples)
    ma_series_with_trend = ma_series + trend
    
    return ma_series, ma_series_with_trend

# Generate data
ma_series, ma_series_with_trend = generate_ma_process(ma_order, ma_n_samples, ma_noise_level)

# Create DataFrame
dates = pd.date_range(start="2020-01-01", periods=ma_n_samples, freq="D")
df = pd.DataFrame({
    "Date": dates,
    "MA_Process": ma_series,
    "MA_Process_With_Trend": ma_series_with_trend,
    "White_Noise": np.random.normal(0, ma_noise_level, ma_n_samples)
})

# Add simple moving average
df['MA_Simple'] = df['MA_Process'].rolling(window=ma_window_size).mean()
df['MA_Simple_Trend'] = df['MA_Process_With_Trend'].rolling(window=ma_window_size).mean()
df['MA_Simple_Noise'] = df['White_Noise'].rolling(window=ma_window_size).mean()

# Plotting function
def plot_series(series_df, cols, title):
    fig, ax = plt.subplots(figsize=(12, 6))
    for col in cols:
        ax.plot(series_df['Date'], series_df[col], label=col)
    ax.set_title(title)
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

# Tabs for different scenarios
tab1, tab2, tab3 = st.tabs([
    "Cas id√©al pour MA", 
    "MA avec tendance (probl√®me)", 
    "Bruit blanc (MA inutile)"
])

with tab1:
    st.header("Cas id√©al pour les Moyennes Mobiles")
    st.markdown("""
    **Quand MA fonctionne bien**: 
    - Lorsque la s√©rie temporelle est stationnaire (pas de tendance, variance constante)
    - Quand les chocs pass√©s ont un effet d√©croissant sur les valeurs futures
    - Pour lisser le bruit et r√©v√©ler les tendances sous-jacentes
    """)
    plot_series(df, ['MA_Process', 'MA_Simple'], 
               "Processus MA pur avec Moyenne Mobile (fonctionne bien)")
    
    st.markdown("""
    **Analyse**:
    - La moyenne mobile suit bien le processus MA sous-jacent
    - Elle permet de lisser les fluctuations tout en capturant la dynamique
    """)

with tab2:
    st.header("Quand les Moyennes Mobiles √©chouent (s√©rie avec tendance)")
    st.markdown("""
    **Probl√®mes**:
    - Les MA simples retardent la d√©tection des tendances
    - Elles sous-estiment syst√©matiquement les valeurs r√©centes en pr√©sence de tendance
    - N√©cessitent des ajustements (diff√©renciation) pour fonctionner correctement
    """)
    plot_series(df, ['MA_Process_With_Trend', 'MA_Simple_Trend'], 
               "Processus MA avec tendance (MA simple √©choue)")
    
    st.markdown("""
    **Solution possible**:
    - Utiliser un mod√®le int√©grant la diff√©renciation (ARIMA)
    - Ou enlever d'abord la tendance avant d'appliquer MA
    """)

with tab3:
    st.header("Bruit blanc - o√π MA n'apporte rien")
    st.markdown("""
    **Pourquoi MA √©choue**:
    - Le bruit blanc n'a aucune structure temporelle
    - La moyenne mobile ne fait que rajouter du d√©lai sans am√©liorer la pr√©diction
    - La meilleure pr√©diction est simplement la moyenne globale
    """)
    plot_series(df, ['White_Noise', 'MA_Simple_Noise'], 
               "Bruit blanc (MA inutile)")
    
    st.markdown("""
    **Analyse**:
    - La moyenne mobile ne fait que lisser le bruit sans r√©v√©ler de pattern
    - La variance est r√©duite mais au prix d'un d√©calage temporel
    - Aucun avantage pr√©dictif dans ce cas
    """)

# Add theoretical explanation
st.sidebar.markdown("""
## Th√©orie des Mod√®les MA
Un mod√®le de Moyenne Mobile (MA) exprime la variable actuelle comme une combinaison lin√©aire des termes d'erreur pass√©s.

Pour un mod√®le MA(q):
$$ X_t = \\mu + \\epsilon_t + \\theta_1\\epsilon_{t-1} + ... + \\theta_q\\epsilon_{t-q} $$

O√π:
- $\\mu$ est la moyenne
- $\\epsilon_t$ est le bruit blanc
- $\\theta_i$ sont les param√®tres du mod√®le
""")

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error
from pandas.plotting import lag_plot


st.title("Visualisation des Mod√®les ARIMA et SARIMA")
st.markdown("""
Cette application montre les performances des mod√®les ARIMA et SARIMA dans diff√©rents sc√©narios temporels.
""")

# Sidebar controls
st.sidebar.header("Param√®tres ARIMA/SARIMA")
col1, col2 = st.sidebar.columns(2)

with col1:
    st.subheader("Param√®tres Non Saisonniers")
    p = st.slider("Ordre AR (p)", 0, 3, 1)
    d = st.slider("Ordre d'int√©gration (d)", 0, 2, 1)
    q = st.slider("Ordre MA (q)", 0, 3, 1)

with col2:
    st.subheader("Param√®tres Saisonniers")
    P = st.slider("Ordre AR saisonnier (P)", 0, 2, 0)
    D = st.slider("Ordre d'int√©gration saisonnier (D)", 0, 1, 0)
    Q = st.slider("Ordre MA saisonnier (Q)", 0, 2, 0)
    m = st.slider("P√©riode saisonni√®re (m)", 1, 24, 12)

n_samples = st.sidebar.slider("Nombre d'√©chantillons", 100, 1000, 200)
noise_level = st.sidebar.slider("Niveau de bruit ", 0.1, 1.0, 0.3)
seasonal_amplitude = st.sidebar.slider("Amplitude saisonni√®re", 0.5, 5.0, 2.0)

# Generate synthetic time series
def generate_time_series_data(n_samples, noise_level, seasonal_amplitude):
    # Base stochastic component
    ar_params = np.array([0.7]*p + [0.0]*(3-p))[:p] if p > 0 else np.array([])
    ma_params = np.array([0.5]*q + [0.0]*(3-q))[:q] if q > 0 else np.array([])
    
    process = ArmaProcess.from_coeffs(ar_params, ma_params)
    stationary = process.generate_sample(n_samples, scale=noise_level)
    
    # Non-stationary series
    non_stationary = np.cumsum(stationary) if d > 0 else stationary.copy()
    
    # Series with deterministic trend
    trend = np.linspace(0, 10, n_samples)
    with_trend = non_stationary + trend
    
    # Random walk
    random_walk = np.cumsum(np.random.normal(0, noise_level, n_samples))
    
    # Seasonal series
    seasonal = stationary + seasonal_amplitude*np.sin(np.linspace(0, 20*np.pi, n_samples))
    
    # Seasonal with trend
    seasonal_trend = seasonal + trend
    
    return {
        'stationary': stationary,
        'non_stationary': non_stationary,
        'with_trend': with_trend,
        'random_walk': random_walk,
        'seasonal': seasonal,
        'seasonal_trend': seasonal_trend
    }

# Generate data
data = generate_time_series_data(n_samples, noise_level, seasonal_amplitude)
dates = pd.date_range(start='2020-01-01', periods=n_samples, freq='D')
df = pd.DataFrame(data, index=dates)

# Train-test split
train_size = int(n_samples * 0.7)
train, test = df.iloc[:train_size], df.iloc[train_size:]

# Model fitting functions
def fit_arima(series, order):
    try:
        model = ARIMA(series, order=order)
        results = model.fit()
        forecast = results.get_forecast(steps=len(test))
        return forecast.predicted_mean, forecast.conf_int(), results
    except Exception as e:
        st.error(f"Erreur ARIMA: {str(e)}")
        return None, None, None

def fit_sarima(series, order, seasonal_order):
    try:
        model = SARIMAX(series, 
                       order=order, 
                       seasonal_order=seasonal_order,
                       enforce_stationarity=False,
                       enforce_invertibility=False)
        results = model.fit(disp=False)
        forecast = results.get_forecast(steps=len(test))
        return forecast.predicted_mean, forecast.conf_int(), results
    except Exception as e:
        st.error(f"Erreur SARIMA: {str(e)}")
        return None, None, None

# Plotting functions
def plot_series(actual, predicted, conf_int, title):
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(actual.index, actual, label='R√©el', color='blue')
    if predicted is not None:
        ax.plot(predicted.index, predicted, label='Pr√©diction', color='red')
        if conf_int is not None:
            ax.fill_between(conf_int.index, 
                           conf_int.iloc[:, 0], 
                           conf_int.iloc[:, 1], 
                           color='pink', alpha=0.3)
    ax.set_title(title)
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

def plot_diagnostics(results):
    if results is None:
        return
        
    fig = plt.figure(figsize=(12, 8))
    layout = (2, 2)
    ax1 = plt.subplot2grid(layout, (0, 0))
    ax2 = plt.subplot2grid(layout, (0, 1))
    ax3 = plt.subplot2grid(layout, (1, 0))
    ax4 = plt.subplot2grid(layout, (1, 1))
    
    residuals = pd.Series(results.resid, index=train.index[:len(results.resid)])
    residuals.plot(ax=ax1, title='R√©sidus')
    ax1.axhline(0, color='red', linestyle='--')
    
    plot_acf(residuals, ax=ax2, title='ACF des R√©sidus')
    
    residuals.plot(kind='kde', ax=ax3, title='Densit√© des R√©sidus')
    
    from statsmodels.graphics.gofplots import qqplot
    qqplot(residuals, line='s', ax=ax4)
    
    plt.tight_layout()
    st.pyplot(fig)

def plot_seasonal_decomposition(series, period):
    from statsmodels.tsa.seasonal import seasonal_decompose
    try:
        result = seasonal_decompose(series, model='additive', period=period)
        fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 8))
        result.observed.plot(ax=ax1, title='Observ√©')
        result.trend.plot(ax=ax2, title='Tendance')
        result.seasonal.plot(ax=ax3, title='Saisonnalit√©')
        result.resid.plot(ax=ax4, title='R√©sidus')
        plt.tight_layout()
        st.pyplot(fig)
    except Exception as e:
        st.error(f"Erreur dans la d√©composition: {str(e)}")

# Tabs for different scenarios
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "Stationnaire", 
    "Non-Stationnaire", 
    "Avec Tendance", 
    "Marche Al√©atoire", 
    "Saisonnier",
    "Saisonnier+Tendance"
])

with tab1:
    st.header("Cas Stationnaire - ARIMA fonctionne bien")
    pred, conf_int, results = fit_arima(train['stationary'], (p, d, q))
    plot_series(df['stationary'], pred, conf_int, "S√©rie Stationnaire - ARIMA")
    
    if results:
        st.write(results.summary())
        mse = mean_squared_error(test['stationary'], pred)
        st.metric("MSE (Test)", f"{mse:.4f}")
        plot_diagnostics(results)

with tab2:
    st.header("S√©rie Non-Stationnaire - ARIMA avec int√©gration")
    pred, conf_int, results = fit_arima(train['non_stationary'], (p, d, q))
    plot_series(df['non_stationary'], pred, conf_int, "S√©rie Non-Stationnaire - ARIMA")
    
    if results:
        mse = mean_squared_error(test['non_stationary'], pred)
        st.metric("MSE (Test)", f"{mse:.4f}")

with tab3:
    st.header("S√©rie avec Tendance - ARIMA standard vs Diff√©renciation")
    pred_arima, conf_int_arima, _ = fit_arima(train['with_trend'], (p, d, q))
    pred_sarima, conf_int_sarima, _ = fit_sarima(
        train['with_trend'], 
        order=(p, d, q),
        seasonal_order=(0, 0, 0, 0)  # No seasonal component
    )
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(df['with_trend'], label='R√©el', color='blue')
    if pred_arima is not None:
        ax.plot(pred_arima.index, pred_arima, label='ARIMA', color='red')
    if pred_sarima is not None:
        ax.plot(pred_sarima.index, pred_sarima, label='ARIMA avec Diff', color='green')
    ax.set_title("Comparaison ARIMA standard vs Diff√©renciation")
    ax.legend()
    st.pyplot(fig)
    
    st.warning("Pour les tendances fortes, la diff√©renciation est cruciale (d=1 ou 2)")

with tab4:
    st.header("Marche Al√©atoire - ARIMA(0,1,0)")
    pred, conf_int, results = fit_arima(train['random_walk'], (0, 1, 0))
    plot_series(df['random_walk'], pred, conf_int, "Marche Al√©atoire - ARIMA(0,1,0)")
    
    st.subheader("Analyse des Lags")
    fig, ax = plt.subplots(figsize=(8, 8))
    lag_plot(df['random_walk'], lag=1, ax=ax)
    st.pyplot(fig)

with tab5:
    st.header("Donn√©es Saisonni√®res - SARIMA requis")
    st.subheader("D√©composition Saisonni√®re")
    plot_seasonal_decomposition(df['seasonal'], period=m)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ARIMA Standard")
        pred_arima, conf_int_arima, _ = fit_arima(train['seasonal'], (p, d, q))
        plot_series(df['seasonal'], pred_arima, conf_int_arima, "ARIMA Standard")
        if pred_arima is not None:
            mse = mean_squared_error(test['seasonal'], pred_arima)
            st.metric("MSE ARIMA", f"{mse:.4f}")
    
    with col2:
        st.subheader("SARIMA")
        pred_sarima, conf_int_sarima, results_sarima = fit_sarima(
            train['seasonal'],
            order=(p, d, q),
            seasonal_order=(P, D, Q, m)
        )
        plot_series(df['seasonal'], pred_sarima, conf_int_sarima, f"SARIMA({P},{D},{Q},{m})")
        if pred_sarima is not None:
            mse = mean_squared_error(test['seasonal'], pred_sarima)
            st.metric("MSE SARIMA", f"{mse:.4f}")
            if results_sarima:
                st.write(results_sarima.summary())

with tab6:
    st.header("Saisonnalit√© + Tendance - SARIMA optimal")
    st.subheader("D√©composition Saisonni√®re")
    plot_seasonal_decomposition(df['seasonal_trend'], period=m)
    
    st.subheader("Comparaison des Mod√®les")
    pred_arima, _, _ = fit_arima(train['seasonal_trend'], (p, d, q))
    pred_sarima, _, results_sarima = fit_sarima(
        train['seasonal_trend'],
        order=(p, d, q),
        seasonal_order=(P, D, Q, m)
    )
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(df['seasonal_trend'], label='R√©el', color='blue')
    if pred_arima is not None:
        ax.plot(pred_arima.index, pred_arima, label='ARIMA', color='red')
    if pred_sarima is not None:
        ax.plot(pred_sarima.index, pred_sarima, label='SARIMA', color='green')
    ax.set_title("Comparaison ARIMA vs SARIMA")
    ax.legend()
    st.pyplot(fig)
    
    if pred_arima is not None and pred_sarima is not None:
        col1, col2 = st.columns(2)
        with col1:
            mse = mean_squared_error(test['seasonal_trend'], pred_arima)
            st.metric("MSE ARIMA", f"{mse:.4f}")
        with col2:
            mse = mean_squared_error(test['seasonal_trend'], pred_sarima)
            st.metric("MSE SARIMA", f"{mse:.4f}")
    
    st.success("SARIMA capture √† la fois la saisonnalit√© et la tendance!")

# ACF/PACF analysis
st.sidebar.subheader("Analyse des Corr√©lations")
selected_series = st.sidebar.selectbox("S√©rie pour ACF/PACF", list(df.columns))

if selected_series:
    st.subheader(f"Analyse ACF/PACF pour {selected_series}")
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    plot_acf(df[selected_series], ax=ax1, lags=40)
    plot_pacf(df[selected_series], ax=ax2, lags=40, method='ywm')
    st.pyplot(fig)

# Model explanation
st.sidebar.markdown("""
## Formulation ARIMA/SARIMA

**ARIMA(p,d,q)**:
$$ (1 - \sum_{i=1}^p \phi_i L^i) (1 - L)^d X_t = (1 + \sum_{i=1}^q \theta_i L^i) \epsilon_t $$

**SARIMA(p,d,q)(P,D,Q)[m]**:
$$ \Phi_P(L^m) \phi_p(L) (1 - L^m)^D (1 - L)^d X_t = \Theta_Q(L^m) \theta_q(L) \epsilon_t $$

O√π:
- $L$: op√©rateur retard
- $m$: p√©riode saisonni√®re
- $\phi$: param√®tres AR
- $\theta$: param√®tres MA
""")







st.title("Visualisation des Arbres de D√©cision en Analyse Pr√©dictive")
st.markdown("""
Cette application montre quand les arbres de d√©cision fonctionnent bien et quand ils √©chouent.
""")

# Sidebar controls
st.sidebar.header("Param√®tres du Mod√®le d'arbres de d√©cision")
problem_type = st.sidebar.radio("Type de probl√®me", ["Classification", "R√©gression"])
max_depth = st.sidebar.slider("Profondeur max de l'arbre", 1, 10, 3)
min_samples_split = st.sidebar.slider("Min samples pour split", 2, 20, 2)
min_samples_leaf = st.sidebar.slider("Min samples par feuille", 1, 10, 1)

# Generate synthetic data based on problem type
def generate_data(problem_type):
    if problem_type == "Classification":
        # Cr√©er 3 types de donn√©es de classification
        X_linear, y_linear = make_classification(
            n_samples=500, n_features=2, n_redundant=0, n_informative=2,
            n_clusters_per_class=1, flip_y=0.1, class_sep=1.0, random_state=42
        )
        
        X_nonlinear, y_nonlinear = make_classification(
            n_samples=500, n_features=2, n_redundant=0, n_informative=2,
            n_clusters_per_class=1, flip_y=0.1, class_sep=0.5, random_state=42
        )
        
        X_xor, y_xor = make_classification(
            n_samples=500, n_features=2, n_redundant=0, n_informative=2,
            n_clusters_per_class=1, flip_y=0.1, class_sep=1.0, random_state=42
        )
        # Modifier pour cr√©er un probl√®me XOR
        X_xor = np.random.randn(500, 2)
        y_xor = np.logical_xor(X_xor[:, 0] > 0, X_xor[:, 1] > 0)
        
        return {
            "Lin√©airement S√©parable": (X_linear, y_linear),
            "Non Lin√©aire": (X_nonlinear, y_nonlinear),
            "Relation XOR": (X_xor, y_xor)
        }
    else:
        # Cr√©er 3 types de donn√©es de r√©gression
        X_linear, y_linear = make_regression(
            n_samples=500, n_features=1, noise=20, random_state=42
        )
        
        X_nonlinear, y_nonlinear = make_regression(
            n_samples=500, n_features=1, noise=10, random_state=42
        )
        y_nonlinear = y_nonlinear + 100 * np.sin(X_nonlinear[:, 0] * 2)
        
        X_multi, y_multi = make_regression(
            n_samples=500, n_features=2, n_informative=2, noise=30, random_state=42
        )
        
        return {
            "Relation Lin√©aire": (X_linear, y_linear),
            "Relation Non Lin√©aire": (X_nonlinear, y_nonlinear),
            "Multiples Variables": (X_multi, y_multi)
        }

# Generate data
data = generate_data(problem_type)

# Train model and plot results
def train_and_plot(X, y, scenario_name, problem_type):
    st.subheader(f"Sc√©nario: {scenario_name}")
    
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )
    
    # Train model
    if problem_type == "Classification":
        model = DecisionTreeClassifier(
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=42
        )
    else:
        model = DecisionTreeRegressor(
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=42
        )
    
    model.fit(X_train, y_train)
    
    # Evaluate
    y_pred = model.predict(X_test)
    
    if problem_type == "Classification":
        accuracy = accuracy_score(y_test, y_pred)
        st.metric("Accuracy", f"{accuracy:.2f}")
        st.text(classification_report(y_test, y_pred))
        
        # Plot decision boundary
        fig, ax = plt.subplots(figsize=(8, 6))
        cmap = ListedColormap(['#FFAAAA', '#AAFFAA'])
        
        if X.shape[1] == 2:
            DecisionBoundaryDisplay.from_estimator(
                model, X, cmap=cmap, alpha=0.8, ax=ax, response_method="predict"
            )
            ax.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', s=20)
            ax.set_title(f"Fronti√®re de d√©cision (Accuracy={accuracy:.2f})")
        else:
            ax.scatter(X[:, 0], y, c=y, edgecolor='k', s=20)
            ax.set_title("Donn√©es de classification")
        
        st.pyplot(fig)
    else:
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        col1, col2 = st.columns(2)
        col1.metric("MSE", f"{mse:.2f}")
        col2.metric("R¬≤ Score", f"{r2:.2f}")
        
        # Plot predictions vs actual
        fig, ax = plt.subplots(figsize=(8, 6))
        
        if X.shape[1] == 1:
            # Trier pour une visualisation propre
            sorted_idx = np.argsort(X_test[:, 0])
            ax.plot(X_test[sorted_idx, 0], y_test[sorted_idx], 'o', label='Vraies valeurs')
            ax.plot(X_test[sorted_idx, 0], y_pred[sorted_idx], '-r', label='Pr√©dictions')
            ax.set_xlabel("Feature")
            ax.set_ylabel("Target")
        else:
            ax.scatter(y_test, y_pred, alpha=0.5)
            ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')
            ax.set_xlabel("Vraies valeurs")
            ax.set_ylabel("Pr√©dictions")
        
        ax.set_title("Pr√©dictions vs Vraies valeurs")
        ax.legend()
        ax.grid(True)
        st.pyplot(fig)
    
    # Plot the tree
    st.subheader("Visualisation de l'arbre de d√©cision")
    fig, ax = plt.subplots(figsize=(20, 10))
    plot_tree(
        model, 
        filled=True, 
        feature_names=[f"Feature {i}" for i in range(X.shape[1])],
        class_names=[str(c) for c in np.unique(y)] if problem_type == "Classification" else None,
        ax=ax
    )
    st.pyplot(fig)

# Main app
tab1, tab2 = st.tabs(["Cas o√π √ßa marche bien", "Cas o√π √ßa marche mal"])

with tab1:
    st.header("Cas o√π les arbres de d√©cision fonctionnent bien")
    if problem_type == "Classification":
        train_and_plot(*data["Lin√©airement S√©parable"], "Donn√©es Lin√©airement S√©parables", problem_type)
    else:
        train_and_plot(*data["Relation Lin√©aire"], "Relation Lin√©aire Simple", problem_type)

with tab2:
    st.header("Cas o√π les arbres de d√©cision ont des difficult√©s")
    if problem_type == "Classification":
        train_and_plot(*data["Relation XOR"], "Relation XOR (Non Lin√©aire Complexe)", problem_type)
    else:
        train_and_plot(*data["Relation Non Lin√©aire"], "Relation Non Lin√©aire Complexe", problem_type)

# Explanation
st.sidebar.markdown("""
## Quand utiliser les arbres de d√©cision?

**Fonctionnent bien quand:**
- Relations non lin√©aires entre features et target
- Donn√©es avec interactions complexes
- Features √† √©chelles diff√©rentes
- Donn√©es avec valeurs manquantes
- Features cat√©gorielles et num√©riques m√©lang√©es

**Fonctionnent mal quand:**
- Relations lin√©aires simples (mod√®les lin√©aires plus efficaces)
- Extrapolation hors du domaine d'entra√Ænement
- Donn√©es avec beaucoup de bruit
- Probl√®mes o√π la relation est XOR-like
- Besoin de mod√®les petits et interpr√©tables (arbres profonds deviennent complexes)
""")